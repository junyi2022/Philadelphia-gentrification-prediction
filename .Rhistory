library(installr)
updateR()
q()
# You can set some global options for knitting chunks
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# Load some libraries
library(tidycensus)
library(tidyverse)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(RColorBrewer)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(spatstat)
library(corrr)
library(classInt)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# Load some libraries
library(tidycensus)
library(tidyverse)
library(dplyr)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(RColorBrewer)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(corrr)
library(classInt)
OPAData <-
read.csv(file.path("https://opendata-downloads.s3.amazonaws.com/opa_properties_public.csv"))
View(OPAData)
class(OPAData)
AssessData <-
read.csv(file.path("https://opendata-downloads.s3.amazonaws.com/assessments.csv"))
Assess2017 <- AssessData[AssessData$year == 2017, ]
Assess2019 <- AssessData[AssessData$year == 2019, ]
Assess2021 <- AssessData[AssessData$year == 2021, ]
PWDparcel <- st_read("https://opendata.arcgis.com/datasets/84baed491de44f539889f2af178ad85c_0.geojson") %>%
st_transform(crs = 2272)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# Load some libraries
library(tidycensus)
library(tidyverse)
library(dplyr)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(RColorBrewer)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(corrr)
library(classInt)
OPAData <-
read.csv(file.path("https://storage.googleapis.com/musa5090s24_team02_public/opa_properties.csv"))
View(OPAData)
PWDparcel <- st_read("https://www.pasda.psu.edu/json/PhillyWater_PWD_PARCELS2023.geojson") %>%
st_transform(crs = 2272)
PWDparcel <- st_read("https://mapservices.pasda.psu.edu/server/rest/services/pasda/CityPhillyWater/MapServer") %>%
st_transform(crs = 2272)
# You can set some global options for knitting chunks
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# Load some libraries
library(tidycensus)
library(tidyverse)
library(dplyr)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(RColorBrewer)
library(dplyr)
library(ggplot2)
library(RColorBrewer)
library(corrr)
library(classInt)
PWDparcel <- st_read("./data/PhillyWater_PWD_PARCELS2023.shp") %>%
st_transform(crs = 2272)
View(PWDparcel)
AssessData[AssessData$objectid == 1586418939, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$TENCODE == 1586418939, ]
AssessData[AssessData$objectid == 1586418939, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$PIN == 1586418939, ]
View(AssessData)
AssessData[AssessData$objectid == 1592199194, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$PIN == 1592199194, ]
AssessData[AssessData$objectid == 1592199194, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$TENCODE == 1592199194, ]
AssessData[AssessData$objectid == 1592199194, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$TENCODE == '1592199194', ]
summary(PWDparcel)
AssessData[AssessData$objectid == 1592199194, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$BRT_ID == 11000001, ]
AssessData[AssessData$objectid == 1592199194, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$TENCODE == 1592199194, ]
class(PWDparcel[PWDparcel$TENCODE == 1592199194, ])
PWDparcel[PWDparcel$TENCODE == 1592199194, ][1]
PWDparcel <- st_read("https://opendata.arcgis.com/datasets/84baed491de44f539889f2af178ad85c_0.geojson") %>%
st_transform(crs = 2272)
PWDparcel %>% group_by(geometry)
AssessData[AssessData$objectid == 4900003710, ]
#OPAData[OPAData$parcel_number == 464423130, ]
PWDparcel[PWDparcel$PARCELID == 11000001, ]
OPAData_geometry <- st_as_sf(OPAData, wkt = "geog")
OPAData_geometry <- st_as_sf(OPAData$geog)
OPAData <-
read.csv(file.path("https://opendata-downloads.s3.amazonaws.com/opa_properties_public.csv"))
OPAData[OPAData$objectid == 4900003710, ]
OPAData[OPAData$objectid == 465006136, ]
AssessData[AssessData$objectid == 465006136, ]
OPAData[OPAData$objectid == 465006136, ]
PWDparcel[PWDparcel$BRT_ID == 465006136, ]
PWDparcel[PWDparcel$PIN == 465006136, ]
PWDparcel[PWDparcel$PIN == '465006136', ]
AssessData[AssessData$objectid == 465006136, ]
OPAData[OPAData$location == '925 W SOMERSET ST', ]
PWDparcel[PWDparcel$ADDRESS == '925 W SOMERSET ST', ]
class(PWDparcel)
class(AssessData)
AssessData[AssessData$parcel_number == 11000001, ]
OPAData[OPAData$parcel_number == 11000001, ]
PWDparcel[PWDparcel$BRT_ID == 11000001, ]
summary(PWDparcel)
AssessData[AssessData$parcel_number == 11000001, ]
OPAData[OPAData$parcel_number == 11000001, ]
PWDparcel[PWDparcel$BRT_ID == '11000001', ]
class(PWDparcel$BRT_ID)
PWDparcel$BRT_ID[1]
PWDparcel$BRT_ID <- as.numeric(PWDparcel$BRT_ID)
PWDparcel$BRT_ID[1]
AssessData[AssessData$parcel_number == 11000001, ]
OPAData[OPAData$parcel_number == 11000001, ]
PWDparcel[PWDparcel$BRT_ID == 11000001, ]
PWDparcel[PWDparcel$BRT_ID == 362307900, ]
AssessData[AssessData$parcel_number == 362307900, ]
OPAData[OPAData$parcel_number == 362307900, ]
PWDparcel[PWDparcel$BRT_ID == 362307900, ]
PWDtest <- PWDparcel[PWDparcel$BRT_ID == 362307900, ]
View(PWDtest)
assess_pwd_join <- left_join(Assess2017, PWDparcel, join_by(parcel_number == BRT_ID))
View(assess_pwd_join)
ggplot()+
geom_sf(data=assess_pwd_join, aes(colour = assess_pwd_join$market_value), size=0.5)+
scale_color_continuous(high = "#6F927F", low = "#b0522a", name= "Sale Price Error ") +
labs(title = "Distribution of Sale Price Error Testing Set") +
theme_void()
assess_pwd_join <- inner_join(Assess2017, PWDparcel, join_by(parcel_number == BRT_ID))
ggplot()+
geom_sf(data=assess_pwd_join, aes(colour = assess_pwd_join$market_value), size=0.5)+
scale_color_continuous(high = "#6F927F", low = "#b0522a", name= "Sale Price Error ") +
labs(title = "Distribution of Sale Price Error Testing Set") +
theme_void()
ggplot()+
geom_sf(data=assess_pwd_join, aes(colour = assess_pwd_join$market_value))
class(assess_pwd_join)
assess_pwd_join <- inner_join(Assess2017, PWDparcel, join_by(parcel_number == BRT_ID)) %>%
st_as_sf(wkt = "geometry")
assess_pwd_join <- inner_join(Assess2017, PWDparcel, join_by(parcel_number == BRT_ID))
sf_object <- st_as_sf(assess_pwd_join, wkt = "geometry")
assess_pwd_join <- inner_join(PWDparcel, Assess2017, join_by(BRT_ID == parcel_number))
class(assess_pwd_join)
ggplot()+
geom_sf(data=assess_pwd_join, aes(colour = assess_pwd_join$market_value))+
scale_color_continuous(high = "#6F927F", low = "#b0522a", name= "Sale Price Error ") +
labs(title = "Distribution of Sale Price Error Testing Set") +
theme_void()
assess_pwd_join_2017 <- inner_join(PWDparcel, Assess2017, join_by(BRT_ID == parcel_number))
ggplot()+
geom_sf(data=assess_pwd_join, aes(colour = assess_pwd_join_2017$market_value))+
scale_fill_continuous(high = "#6F927F", low = "#b0522a", name= "") +
labs(title = "Distribution of Sale Price Error Testing Set") +
theme_void()
class(assess_pwd_join_2017$market_value)
ggplot()+
geom_sf(data=assess_pwd_join_2017, aes(colour = assess_pwd_join_2017$market_value))+
scale_fill_continuous(high = "#6F927F", low = "#b0522a", name= "") +
labs(title = "Distribution of Sale Price Error Testing Set") +
theme_void()
View(assess_pwd_join_2017)
ggplot()+
geom_sf(data=assess_pwd_join_2017, aes(colour = assess_pwd_join_2017$market_value))
ggplot()+
geom_sf(data=assess_pwd_join_2017, aes(fill = market_value), color = NA) +
#scale_fill_gradientn(colors = my_colors, na.value = "#e9e9e9",
#                    name = "Count of Assaults") +
labs(title = "Count of Assaults for the fishnet",
caption = "Data: Chicago Data Portal Crimes 2022") +
theme_void()
summary(assess_pwd_join_2017$market_value)
my_colors <- c("#033E56", "#518984", "#9DC9A3", "#F5CD42", "#F5A70A", "#D05A30")
ggplot()+
geom_sf(data=assess_pwd_join_2017, aes(fill = market_value), color = NA) +
scale_fill_gradientn(colors = my_colors, na.value = "#e9e9e9",
name = "Count of Assaults") +
labs(title = "Count of Assaults for the fishnet",
caption = "Data: Chicago Data Portal Crimes 2022") +
theme_void()
# Define the number of quantiles
num_quantiles <- 5
# Cut the market_value variable into quantiles
assess_pwd_join_2017$quantile <- cut(assess_pwd_join_2017$market_value,
breaks = num_quantiles, labels = FALSE)
# Plot with color by quantile
ggplot() +
geom_sf(data = assess_pwd_join_2017, aes(fill = as.factor(quantile)), color = NA) +
scale_fill_manual(values = my_colors,
name = "Quantile",
labels = paste("Quantile", 1:num_quantiles)) +
labs(title = "Count of Assaults for the fishnet",
caption = "Data: Chicago Data Portal Crimes 2022") +
theme_void()
tm_shape(assess_pwd_join_2017) +
tm_polygons(fill = "market_value", style = "quantile", border.col = "#f7f7f7", border.lwd = 0.5, n=6,title = "Population Density (n/mile)", palette = "BuPu" )+
tm_layout(frame = FALSE,legend.frame = FALSE)+
tm_title("2009 Population Density in Suffolk County") +
tm_credits("Data source: 2009 5-year ACS, US Census Bureau")
library(tmap)
tm_shape(assess_pwd_join_2017) +
tm_polygons(fill = "market_value", style = "quantile", border.col = "#f7f7f7", border.lwd = 0.5, n=6,title = "Population Density (n/mile)", palette = "BuPu" )+
tm_layout(frame = FALSE,legend.frame = FALSE)+
tm_title("2009 Population Density in Suffolk County") +
tm_credits("Data source: 2009 5-year ACS, US Census Bureau")
install.packages("remotes")
library(remotes)
install_github("r-tmap/tmap", force = TRUE)
tm_shape(assess_pwd_join_2017) +
tm_polygons(fill = "market_value", style = "quantile", border.col = "#f7f7f7", border.lwd = 0.5, n=6,title = "Population Density (n/mile)", palette = "BuPu" )+
tm_layout(frame = FALSE,legend.frame = FALSE)+
tm_title("2009 Population Density in Suffolk County") +
tm_credits("Data source: 2009 5-year ACS, US Census Bureau")
tm_shape(assess_pwd_join_2017) +
tm_polygons(fill = "market_value", style = "quantile", border.col = "#f7f7f7", border.lwd = 0.5, n=6,title = "Population Density (n/mile)", palette = "BuPu" )+
tm_layout(frame = FALSE,legend.frame = FALSE)+
tm_title("2009 Population Density in Suffolk County") +
tm_credits("Data source: 2009 5-year ACS, US Census Bureau")
